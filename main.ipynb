{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "698ccf15",
   "metadata": {},
   "source": [
    "# Main experiment\n",
    "\n",
    "## imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33bc47c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16a483c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from src.pgr_experiment import *\n",
    "from src.utils import choose_indices\n",
    "from src.config import MODELS_LIST\n",
    "from src.math_dataset import load_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2676996",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = load_questions(\"train\", limit=100)\n",
    "test_ds = load_questions(\"test\", limit=100)\n",
    "indices = choose_indices(len(train_ds), 3, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc277e9",
   "metadata": {},
   "source": [
    "## Compare Performance of each model on MATH dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbf97b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments for model: gpt-5-mini\n",
      "Mean score: 0.9466666666666667, Std: 0.01527525231651942\n",
      "Running experiments for model: o3-mini\n",
      "Mean score: 0.8366666666666666, Std: 0.011547005383792525\n",
      "Running experiments for model: gpt-4.1-mini\n",
      "Mean score: 0.9166666666666666, Std: 0.02081665999466128\n",
      "Running experiments for model: gpt-4o-mini\n",
      "Mean score: 0.5233333333333333, Std: 0.005773502691896262\n",
      "Running experiments for model: gpt-4.1-nano\n",
      "Mean score: 0.7799999999999999, Std: 0.01732050807568879\n",
      "{'gpt-5-mini': {'mean': 0.9466666666666667, 'std': np.float64(0.01527525231651942)}, 'o3-mini': {'mean': 0.8366666666666666, 'std': np.float64(0.011547005383792525)}, 'gpt-4.1-mini': {'mean': 0.9166666666666666, 'std': np.float64(0.02081665999466128)}, 'gpt-4o-mini': {'mean': 0.5233333333333333, 'std': np.float64(0.005773502691896262)}, 'gpt-4.1-nano': {'mean': 0.7799999999999999, 'std': np.float64(0.01732050807568879)}}\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for model in MODELS_LIST:\n",
    "    print(f\"Running experiments for model: {model}\")\n",
    "    scores = []\n",
    "    for _ in range(3):\n",
    "        score = await ask_with_gold(model, train_ds, test_ds, indices)\n",
    "        scores.append(score)\n",
    "    results[model] = {\"mean\": sum(scores) / len(scores), \"std\": np.std(scores, ddof=1)}\n",
    "    print(f\"Mean score: {results[model]['mean']:.3f}, Std: {results[model]['std']:.3f}\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b574181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "with open(\"results/model_math_performance.json\", \"w\") as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca2e2b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['gpt-5-mini', 0.9466666666666667],\n",
       " ['o3-mini', 0.8366666666666666],\n",
       " ['gpt-4.1-mini', 0.9166666666666666],\n",
       " ['gpt-4o-mini', 0.5233333333333333],\n",
       " ['gpt-4.1-nano', 0.7799999999999999]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[k, v[\"mean\"]] for k, v in results.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aba3eed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_results = pd.DataFrame(columns=[\"weak_model\", \"strong_model\", \"mean_pgr\", \"std_pgr\"])\n",
    "\n",
    "ordered_models = sorted(MODELS_LIST, key=lambda m: results[m][\"mean\"], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbc142bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cross model PGR: weak=gpt-4.1-mini, strong=gpt-5-mini\n",
      "Acc (strong model with weak labels): 0.9600\n",
      "Acc (strong model with gold labels): 0.9400\n",
      "Acc (weak model with gold labels): 0.9200\n",
      "Acc (strong model with weak labels): 0.9600\n",
      "Acc (strong model with gold labels): 0.9600\n",
      "Acc (weak model with gold labels): 0.9000\n",
      "Acc (strong model with weak labels): 0.9800\n",
      "Acc (strong model with gold labels): 0.9400\n",
      "Acc (weak model with gold labels): 0.9200\n",
      "PGR: 1.000 ± 0.000\n",
      "Running cross model PGR: weak=o3-mini, strong=gpt-5-mini\n",
      "Acc (strong model with weak labels): 0.9400\n",
      "Acc (strong model with gold labels): 0.9800\n",
      "Acc (weak model with gold labels): 0.8600\n",
      "Acc (strong model with weak labels): 0.9600\n",
      "Acc (strong model with gold labels): 0.9400\n",
      "Acc (weak model with gold labels): 0.8600\n",
      "Acc (strong model with weak labels): 0.9600\n",
      "Acc (strong model with gold labels): 0.9600\n",
      "Acc (weak model with gold labels): 0.8400\n",
      "PGR: 0.889 ± 0.157\n",
      "Running cross model PGR: weak=gpt-4.1-nano, strong=gpt-5-mini\n",
      "Acc (strong model with weak labels): 0.9400\n",
      "Acc (strong model with gold labels): 0.9800\n",
      "Acc (weak model with gold labels): 0.8000\n",
      "Acc (strong model with weak labels): 0.9600\n",
      "Acc (strong model with gold labels): 0.9400\n",
      "Acc (weak model with gold labels): 0.8000\n",
      "Acc (strong model with weak labels): 0.9600\n",
      "Acc (strong model with gold labels): 0.9600\n",
      "Acc (weak model with gold labels): 0.7600\n",
      "PGR: 0.926 ± 0.105\n",
      "Running cross model PGR: weak=gpt-4o-mini, strong=gpt-5-mini\n",
      "Acc (strong model with weak labels): 0.9400\n",
      "Acc (strong model with gold labels): 0.9800\n",
      "Acc (weak model with gold labels): 0.5800\n",
      "Acc (strong model with weak labels): 0.9800\n",
      "Acc (strong model with gold labels): 0.9800\n",
      "Acc (weak model with gold labels): 0.5400\n",
      "Acc (strong model with weak labels): 0.9800\n",
      "Acc (strong model with gold labels): 0.9600\n",
      "Acc (weak model with gold labels): 0.5400\n",
      "PGR: 0.967 ± 0.047\n"
     ]
    }
   ],
   "source": [
    "logs = {}\n",
    "strong_model = ordered_models[0]\n",
    "strong_mean = results[strong_model][\"mean\"]\n",
    "for weak_model in ordered_models:\n",
    "    if weak_model == strong_model:\n",
    "        continue\n",
    "    weak_mean = results[weak_model][\"mean\"]\n",
    "    if weak_mean >= strong_mean:\n",
    "        continue  # skip models with equal or higher accuracy\n",
    "    print(f\"Running cross model PGR: weak={weak_model}, strong={strong_model}\")\n",
    "    pgrs = []\n",
    "    logs[(weak_model, strong_model)] = {}\n",
    "    for i in range(3):\n",
    "        pgr, acc_strong_weak, acc_strong_gold, acc_weak_gold = await run_pgr_experiment(\n",
    "            weak_model,\n",
    "            strong_model,\n",
    "            train_ds,\n",
    "            test_ds[:50],\n",
    "            indices,\n",
    "            verbose=True\n",
    "        )\n",
    "        pgrs.append(pgr)\n",
    "        logs[(weak_model, strong_model)][i] = {\n",
    "            \"pgr\": pgr,\n",
    "            \"acc_strong_weak\": acc_strong_weak,\n",
    "            \"acc_strong_gold\": acc_strong_gold,\n",
    "            \"acc_weak_gold\": acc_weak_gold\n",
    "        }\n",
    "    cross_results.loc[len(cross_results.index)] = [weak_model, strong_model, np.mean(pgrs), np.std(pgrs)]\n",
    "    print(f\"PGR: {np.mean(pgrs):.3f} ± {np.std(pgrs):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4aefca49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cross model PGR: weak=o3-mini, strong=gpt-4.1-mini\n",
      "Acc (strong model with weak labels): 0.8800\n",
      "Acc (strong model with gold labels): 0.9200\n",
      "Acc (weak model with gold labels): 0.8200\n",
      "Acc (strong model with weak labels): 0.9400\n",
      "Acc (strong model with gold labels): 0.9400\n",
      "Acc (weak model with gold labels): 0.8200\n",
      "Acc (strong model with weak labels): 0.9600\n",
      "Acc (strong model with gold labels): 0.9200\n",
      "Acc (weak model with gold labels): 0.8000\n",
      "PGR: 0.867 ± 0.189\n",
      "Running cross model PGR: weak=gpt-4.1-nano, strong=gpt-4.1-mini\n",
      "Acc (strong model with weak labels): 0.9600\n",
      "Acc (strong model with gold labels): 0.9200\n",
      "Acc (weak model with gold labels): 0.7800\n",
      "Acc (strong model with weak labels): 0.9200\n",
      "Acc (strong model with gold labels): 0.9000\n",
      "Acc (weak model with gold labels): 0.7400\n",
      "Acc (strong model with weak labels): 0.9200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error in configuration: macro '\\frac' failed its substitution!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc (strong model with gold labels): 0.9000\n",
      "Acc (weak model with gold labels): 0.7600\n",
      "PGR: 1.000 ± 0.000\n",
      "Running cross model PGR: weak=gpt-4o-mini, strong=gpt-4.1-mini\n",
      "Acc (strong model with weak labels): 0.9200\n",
      "Acc (strong model with gold labels): 0.9000\n",
      "Acc (weak model with gold labels): 0.5800\n",
      "Acc (strong model with weak labels): 0.9000\n",
      "Acc (strong model with gold labels): 0.9400\n",
      "Acc (weak model with gold labels): 0.5600\n",
      "Acc (strong model with weak labels): 0.9200\n",
      "Acc (strong model with gold labels): 0.9000\n",
      "Acc (weak model with gold labels): 0.5800\n",
      "PGR: 0.965 ± 0.050\n"
     ]
    }
   ],
   "source": [
    "strong_model = ordered_models[1]  # update strong model\n",
    "strong_mean = results[strong_model][\"mean\"]\n",
    "for weak_model in ordered_models:\n",
    "    if weak_model == strong_model:\n",
    "        continue\n",
    "    weak_mean = results[weak_model][\"mean\"]\n",
    "    if weak_mean >= strong_mean:\n",
    "        continue  # skip models with equal or higher accuracy\n",
    "    print(f\"Running cross model PGR: weak={weak_model}, strong={strong_model}\")\n",
    "    pgrs = []\n",
    "    logs[(weak_model, strong_model)] = {}\n",
    "    for i in range(3):\n",
    "        pgr, acc_strong_weak, acc_strong_gold, acc_weak_gold = await run_pgr_experiment(\n",
    "            weak_model,\n",
    "            strong_model,\n",
    "            train_ds,\n",
    "            test_ds[:50],\n",
    "            indices,\n",
    "            verbose=True\n",
    "        )\n",
    "        pgrs.append(pgr)\n",
    "        logs[(weak_model, strong_model)][i] = {\n",
    "            \"pgr\": pgr,\n",
    "            \"acc_strong_weak\": acc_strong_weak,\n",
    "            \"acc_strong_gold\": acc_strong_gold,\n",
    "            \"acc_weak_gold\": acc_weak_gold\n",
    "        }\n",
    "    cross_results.loc[len(cross_results.index)] = [weak_model, strong_model, np.mean(pgrs), np.std(pgrs)]\n",
    "    print(f\"PGR: {np.mean(pgrs):.3f} ± {np.std(pgrs):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7a837d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cross model PGR: weak=gpt-4.1-nano, strong=o3-mini\n",
      "Acc (strong model with weak labels): 0.8400\n",
      "Acc (strong model with gold labels): 0.8800\n",
      "Acc (weak model with gold labels): 0.7800\n",
      "Acc (strong model with weak labels): 0.8600\n",
      "Acc (strong model with gold labels): 0.8400\n",
      "Acc (weak model with gold labels): 0.8000\n",
      "Acc (strong model with weak labels): 0.8200\n",
      "Acc (strong model with gold labels): 0.8400\n",
      "Acc (weak model with gold labels): 0.7800\n",
      "PGR: 0.756 ± 0.175\n",
      "Running cross model PGR: weak=gpt-4o-mini, strong=o3-mini\n",
      "Acc (strong model with weak labels): 0.8400\n",
      "Acc (strong model with gold labels): 0.8200\n",
      "Acc (weak model with gold labels): 0.5600\n",
      "Acc (strong model with weak labels): 0.8400\n",
      "Acc (strong model with gold labels): 0.8200\n",
      "Acc (weak model with gold labels): 0.5400\n",
      "Acc (strong model with weak labels): 0.8000\n",
      "Acc (strong model with gold labels): 0.9000\n",
      "Acc (weak model with gold labels): 0.6400\n",
      "PGR: 0.872 ± 0.181\n"
     ]
    }
   ],
   "source": [
    "strong_model = ordered_models[2]  # update strong model\n",
    "strong_mean = results[strong_model][\"mean\"]\n",
    "for weak_model in ordered_models:\n",
    "    if weak_model == strong_model:\n",
    "        continue\n",
    "    weak_mean = results[weak_model][\"mean\"]\n",
    "    if weak_mean >= strong_mean:\n",
    "        continue  # skip models with equal or higher accuracy\n",
    "    print(f\"Running cross model PGR: weak={weak_model}, strong={strong_model}\")\n",
    "    pgrs = []\n",
    "    logs[(weak_model, strong_model)] = {}\n",
    "    for i in range(3):\n",
    "        pgr, acc_strong_weak, acc_strong_gold, acc_weak_gold = await run_pgr_experiment(\n",
    "            weak_model,\n",
    "            strong_model,\n",
    "            train_ds,\n",
    "            test_ds[:50],\n",
    "            indices,\n",
    "            verbose=True\n",
    "        )\n",
    "        pgrs.append(pgr)\n",
    "        logs[(weak_model, strong_model)][i] = {\n",
    "            \"pgr\": pgr,\n",
    "            \"acc_strong_weak\": acc_strong_weak,\n",
    "            \"acc_strong_gold\": acc_strong_gold,\n",
    "            \"acc_weak_gold\": acc_weak_gold\n",
    "        }\n",
    "    cross_results.loc[len(cross_results.index)] = [weak_model, strong_model, np.mean(pgrs), np.std(pgrs)]\n",
    "    print(f\"PGR: {np.mean(pgrs):.3f} ± {np.std(pgrs):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5700ba6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cross model PGR: weak=gpt-4o-mini, strong=gpt-4.1-nano\n",
      "Acc (strong model with weak labels): 0.7800\n",
      "Acc (strong model with gold labels): 0.8000\n",
      "Acc (weak model with gold labels): 0.5400\n",
      "Acc (strong model with weak labels): 0.8400\n",
      "Acc (strong model with gold labels): 0.8000\n",
      "Acc (weak model with gold labels): 0.5400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error in configuration: macro '\\frac' failed its substitution!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc (strong model with weak labels): 0.8000\n",
      "Acc (strong model with gold labels): 0.7200\n",
      "Acc (weak model with gold labels): 0.6000\n",
      "PGR: 0.974 ± 0.036\n"
     ]
    }
   ],
   "source": [
    "strong_model = ordered_models[3]  # update strong model\n",
    "strong_mean = results[strong_model][\"mean\"]\n",
    "for weak_model in ordered_models:\n",
    "    if weak_model == strong_model:\n",
    "        continue\n",
    "    weak_mean = results[weak_model][\"mean\"]\n",
    "    if weak_mean >= strong_mean:\n",
    "        continue  # skip models with equal or higher accuracy\n",
    "    print(f\"Running cross model PGR: weak={weak_model}, strong={strong_model}\")\n",
    "    pgrs = []\n",
    "    logs[(weak_model, strong_model)] = {}\n",
    "    for i in range(3):\n",
    "        pgr, acc_strong_weak, acc_strong_gold, acc_weak_gold = await run_pgr_experiment(\n",
    "            weak_model,\n",
    "            strong_model,\n",
    "            train_ds,\n",
    "            test_ds[:50],\n",
    "            indices,\n",
    "            verbose=True\n",
    "        )\n",
    "        pgrs.append(pgr)\n",
    "        logs[(weak_model, strong_model)][i] = {\n",
    "            \"pgr\": pgr,\n",
    "            \"acc_strong_weak\": acc_strong_weak,\n",
    "            \"acc_strong_gold\": acc_strong_gold,\n",
    "            \"acc_weak_gold\": acc_weak_gold\n",
    "        }\n",
    "    cross_results.loc[len(cross_results.index)] = [weak_model, strong_model, np.nanmean(pgrs), np.nanstd(pgrs)]\n",
    "    print(f\"PGR: {np.mean(pgrs):.3f} ± {np.std(pgrs):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9337ae7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('gpt-4.1-mini',\n",
       "  'gpt-5-mini'): {0: {'pgr': 1.0,\n",
       "   'acc_strong_weak': 0.96,\n",
       "   'acc_strong_gold': 0.94,\n",
       "   'acc_weak_gold': 0.92}, 1: {'pgr': 1.0,\n",
       "   'acc_strong_weak': 0.96,\n",
       "   'acc_strong_gold': 0.96,\n",
       "   'acc_weak_gold': 0.9}, 2: {'pgr': 1.0,\n",
       "   'acc_strong_weak': 0.98,\n",
       "   'acc_strong_gold': 0.94,\n",
       "   'acc_weak_gold': 0.92}},\n",
       " ('o3-mini',\n",
       "  'gpt-5-mini'): {0: {'pgr': 0.6666666666666664,\n",
       "   'acc_strong_weak': 0.94,\n",
       "   'acc_strong_gold': 0.98,\n",
       "   'acc_weak_gold': 0.86}, 1: {'pgr': 1.0,\n",
       "   'acc_strong_weak': 0.96,\n",
       "   'acc_strong_gold': 0.94,\n",
       "   'acc_weak_gold': 0.86}, 2: {'pgr': 1.0,\n",
       "   'acc_strong_weak': 0.96,\n",
       "   'acc_strong_gold': 0.96,\n",
       "   'acc_weak_gold': 0.84}},\n",
       " ('gpt-4.1-nano',\n",
       "  'gpt-5-mini'): {0: {'pgr': 0.7777777777777775,\n",
       "   'acc_strong_weak': 0.94,\n",
       "   'acc_strong_gold': 0.98,\n",
       "   'acc_weak_gold': 0.8}, 1: {'pgr': 1.0,\n",
       "   'acc_strong_weak': 0.96,\n",
       "   'acc_strong_gold': 0.94,\n",
       "   'acc_weak_gold': 0.8}, 2: {'pgr': 1.0,\n",
       "   'acc_strong_weak': 0.96,\n",
       "   'acc_strong_gold': 0.96,\n",
       "   'acc_weak_gold': 0.76}},\n",
       " ('gpt-4o-mini',\n",
       "  'gpt-5-mini'): {0: {'pgr': 0.8999999999999999,\n",
       "   'acc_strong_weak': 0.94,\n",
       "   'acc_strong_gold': 0.98,\n",
       "   'acc_weak_gold': 0.58}, 1: {'pgr': 1.0,\n",
       "   'acc_strong_weak': 0.98,\n",
       "   'acc_strong_gold': 0.98,\n",
       "   'acc_weak_gold': 0.54}, 2: {'pgr': 1.0,\n",
       "   'acc_strong_weak': 0.98,\n",
       "   'acc_strong_gold': 0.96,\n",
       "   'acc_weak_gold': 0.54}},\n",
       " ('o3-mini',\n",
       "  'gpt-4.1-mini'): {0: {'pgr': 0.6,\n",
       "   'acc_strong_weak': 0.88,\n",
       "   'acc_strong_gold': 0.92,\n",
       "   'acc_weak_gold': 0.82}, 1: {'pgr': 1.0,\n",
       "   'acc_strong_weak': 0.94,\n",
       "   'acc_strong_gold': 0.94,\n",
       "   'acc_weak_gold': 0.82}, 2: {'pgr': 1.0,\n",
       "   'acc_strong_weak': 0.96,\n",
       "   'acc_strong_gold': 0.92,\n",
       "   'acc_weak_gold': 0.8}},\n",
       " ('gpt-4.1-nano',\n",
       "  'gpt-4.1-mini'): {0: {'pgr': 1.0,\n",
       "   'acc_strong_weak': 0.96,\n",
       "   'acc_strong_gold': 0.92,\n",
       "   'acc_weak_gold': 0.78}, 1: {'pgr': 1.0,\n",
       "   'acc_strong_weak': 0.92,\n",
       "   'acc_strong_gold': 0.9,\n",
       "   'acc_weak_gold': 0.74}, 2: {'pgr': 1.0,\n",
       "   'acc_strong_weak': 0.92,\n",
       "   'acc_strong_gold': 0.9,\n",
       "   'acc_weak_gold': 0.76}},\n",
       " ('gpt-4o-mini',\n",
       "  'gpt-4.1-mini'): {0: {'pgr': 1.0,\n",
       "   'acc_strong_weak': 0.92,\n",
       "   'acc_strong_gold': 0.9,\n",
       "   'acc_weak_gold': 0.58}, 1: {'pgr': 0.8947368421052633,\n",
       "   'acc_strong_weak': 0.9,\n",
       "   'acc_strong_gold': 0.94,\n",
       "   'acc_weak_gold': 0.56}, 2: {'pgr': 1.0,\n",
       "   'acc_strong_weak': 0.92,\n",
       "   'acc_strong_gold': 0.9,\n",
       "   'acc_weak_gold': 0.58}},\n",
       " ('gpt-4.1-nano',\n",
       "  'o3-mini'): {0: {'pgr': 0.5999999999999995,\n",
       "   'acc_strong_weak': 0.84,\n",
       "   'acc_strong_gold': 0.88,\n",
       "   'acc_weak_gold': 0.78}, 1: {'pgr': 1.0,\n",
       "   'acc_strong_weak': 0.86,\n",
       "   'acc_strong_gold': 0.84,\n",
       "   'acc_weak_gold': 0.8}, 2: {'pgr': 0.6666666666666661,\n",
       "   'acc_strong_weak': 0.82,\n",
       "   'acc_strong_gold': 0.84,\n",
       "   'acc_weak_gold': 0.78}},\n",
       " ('gpt-4o-mini',\n",
       "  'o3-mini'): {0: {'pgr': 1.0,\n",
       "   'acc_strong_weak': 0.84,\n",
       "   'acc_strong_gold': 0.82,\n",
       "   'acc_weak_gold': 0.56}, 1: {'pgr': 1.0,\n",
       "   'acc_strong_weak': 0.84,\n",
       "   'acc_strong_gold': 0.82,\n",
       "   'acc_weak_gold': 0.54}, 2: {'pgr': 0.6153846153846155,\n",
       "   'acc_strong_weak': 0.8,\n",
       "   'acc_strong_gold': 0.9,\n",
       "   'acc_weak_gold': 0.64}},\n",
       " ('gpt-4o-mini',\n",
       "  'gpt-4.1-nano'): {0: {'pgr': 0.923076923076923,\n",
       "   'acc_strong_weak': 0.78,\n",
       "   'acc_strong_gold': 0.8,\n",
       "   'acc_weak_gold': 0.54}, 1: {'pgr': 1.0,\n",
       "   'acc_strong_weak': 0.84,\n",
       "   'acc_strong_gold': 0.8,\n",
       "   'acc_weak_gold': 0.54}, 2: {'pgr': 1.0,\n",
       "   'acc_strong_weak': 0.8,\n",
       "   'acc_strong_gold': 0.72,\n",
       "   'acc_weak_gold': 0.6}}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88fdd834",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_results.to_csv(\"results/cross_model_math_pgr.csv\")\n",
    "with open(\"logs/cross_model_logs.json\", \"w\") as f:\n",
    "    # Convert tuple keys to strings for JSON serialization\n",
    "    logs_str_keys = {str(k): v for k, v in logs.items()}\n",
    "    json.dump(logs_str_keys, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59314fe",
   "metadata": {},
   "source": [
    "## K Few shot experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9c8dd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments with k=0 few-shots...\n",
      "Acc (strong model with weak labels): 0.9600\n",
      "Acc (strong model with gold labels): 0.9400\n",
      "Acc (weak model with gold labels): 0.8200\n",
      "Acc (strong model with weak labels): 0.9800\n",
      "Acc (strong model with gold labels): 0.9200\n",
      "Acc (weak model with gold labels): 0.8000\n",
      "Acc (strong model with weak labels): 0.9200\n",
      "Acc (strong model with gold labels): 0.9200\n",
      "Acc (weak model with gold labels): 0.8200\n",
      "[1.0, 1.0, 1.0]\n",
      "Mean PGR: 1.0, Std: 0.0\n",
      "Running experiments with k=2 few-shots...\n",
      "Acc (strong model with weak labels): 0.9400\n",
      "Acc (strong model with gold labels): 0.9800\n",
      "Acc (weak model with gold labels): 0.8000\n",
      "Acc (strong model with weak labels): 0.9400\n",
      "Acc (strong model with gold labels): 0.9200\n",
      "Acc (weak model with gold labels): 0.8200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error in configuration: macro '\\frac' failed its substitution!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc (strong model with weak labels): 0.9000\n",
      "Acc (strong model with gold labels): 0.9400\n",
      "Acc (weak model with gold labels): 0.8000\n",
      "[0.7777777777777775, 1.0, 0.7142857142857146]\n",
      "Mean PGR: 0.8306878306878307, Std: 0.15002589289690813\n",
      "Running experiments with k=4 few-shots...\n",
      "Acc (strong model with weak labels): 0.9400\n",
      "Acc (strong model with gold labels): 0.9000\n",
      "Acc (weak model with gold labels): 0.8000\n",
      "Acc (strong model with weak labels): 0.8800\n",
      "Acc (strong model with gold labels): 0.9000\n",
      "Acc (weak model with gold labels): 0.8000\n",
      "Acc (strong model with weak labels): 0.9000\n",
      "Acc (strong model with gold labels): 0.8600\n",
      "Acc (weak model with gold labels): 0.8000\n",
      "[1.0, 0.7999999999999998, 1.0]\n",
      "Mean PGR: 0.9333333333333332, Std: 0.11547005383792526\n"
     ]
    }
   ],
   "source": [
    "k_few_shot_results = {}\n",
    "logs = {}\n",
    "for k in range(0, 6, 2):\n",
    "    print(f\"Running experiments with k={k} few-shots...\")\n",
    "    indices = choose_indices(len(train_ds), k, seed=42)\n",
    "    pgrs = []\n",
    "    logs[k] = {}\n",
    "    for i in range(3):\n",
    "        pgr, acc_strong_weak, acc_strong_gold, acc_weak_gold = await run_pgr_experiment(\n",
    "            \"o3-mini\",\n",
    "            \"gpt-4.1-mini\",\n",
    "            train_ds,\n",
    "            test_ds[:50],\n",
    "            indices,\n",
    "            verbose=True\n",
    "        )\n",
    "        pgrs.append(pgr)\n",
    "        logs[k][i] = {\n",
    "            \"pgr\": pgr,\n",
    "            \"acc_strong_weak\": acc_strong_weak,\n",
    "            \"acc_strong_gold\": acc_strong_gold,\n",
    "            \"acc_weak_gold\": acc_weak_gold\n",
    "        }\n",
    "    mean_pgr = np.nanmean(pgrs)\n",
    "    std_pgr = np.nanstd(pgrs, ddof=1)\n",
    "    print(pgrs)\n",
    "    print(f\"Mean PGR: {mean_pgr}, Std: {std_pgr}\")\n",
    "    results[k] = {\"mean\": mean_pgr, \"std\": std_pgr}\n",
    "\n",
    "with open(\"logs/few_shot_logs.json\", \"w\") as f:\n",
    "    json.dump(logs, f)\n",
    "with open(\"results/few_shot_performance.json\", \"w\") as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dad9bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
